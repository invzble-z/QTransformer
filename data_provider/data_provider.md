# Data Provider - Há»‡ thá»‘ng Quáº£n lÃ½ vÃ  Cung cáº¥p Dá»¯ liá»‡u

## Tá»•ng quan
Folder `data_provider` chá»©a toÃ n bá»™ há»‡ thá»‘ng quáº£n lÃ½ vÃ  cung cáº¥p dá»¯ liá»‡u cho mÃ´ hÃ¬nh QTransformer. ÄÃ¢y lÃ  layer trung gian giá»¯a dá»¯ liá»‡u thÃ´ vÃ  mÃ´ hÃ¬nh, chá»‹u trÃ¡ch nhiá»‡m load, xá»­ lÃ½, vÃ  chuáº©n bá»‹ dá»¯ liá»‡u theo Ä‘Ãºng format yÃªu cáº§u.

## Kiáº¿n trÃºc Há»‡ thá»‘ng

### ğŸ­ Data Factory Pattern
File `data_factory.py` hoáº¡t Ä‘á»™ng theo **Factory Pattern**, tá»± Ä‘á»™ng táº¡o ra Ä‘Ãºng loáº¡i dataset vÃ  dataloader dá»±a trÃªn cáº¥u hÃ¬nh:

```python
data_dict = {
    'SupplyChainEmbedding': Dataset_SupplyChain_Embedding,      # Embedding approach
    'MultiRegionEmbedding': Dataset_MultiRegion_Embedding,      # Multi-region embedding  
    'SupplyChainProcessed': Dataset_SupplyChain_Processed,      # Standard approach
    'SupplyChainMultiMarket': Dataset_SupplyChain_MultiMarket,  # Multi-market approach
    'SupplyChainOptimized': Dataset_SupplyChain_Processed       # Optimized version
}
```

**Nhiá»‡m vá»¥ chÃ­nh:**
- **Tá»± Ä‘á»™ng chá»n dataset**: Dá»±a trÃªn `args.data` Ä‘á»ƒ chá»n Ä‘Ãºng class dataset
- **Cáº¥u hÃ¬nh dataloader**: Batch size, shuffle, num_workers, collate function
- **Xá»­ lÃ½ embedding data**: Custom collate function cho categorical features
- **Train/Val/Test split**: Tá»± Ä‘á»™ng chia dá»¯ liá»‡u theo tá»· lá»‡ chuáº©n

### ğŸ“Š Dataset Classes

#### 1. **Dataset_SupplyChain_Embedding** (Approach chÃ­nh - Phase 1)
**File:** `data_loader_embedding.py`

**Má»¥c Ä‘Ã­ch:** Xá»­ lÃ½ dá»¯ liá»‡u supply chain vá»›i embedding cho categorical features

**TÃ­nh nÄƒng ná»•i báº­t:**
- **Categorical Embedding**: Chuyá»ƒn Ä‘á»•i categorical variables (Region, Category, etc.) thÃ nh embedding vectors
- **Mixed Data Handling**: Xá»­ lÃ½ Ä‘á»“ng thá»i numerical vÃ  categorical features
- **Flexible Feature Selection**: Há»— trá»£ 'MS' (multivariate), 'M' (univariate), 'S' (single target)
- **Scaling Integration**: Tá»± Ä‘á»™ng normalize numerical features
- **Time Encoding**: Chuyá»ƒn Ä‘á»•i timestamp thÃ nh time features

**Workflow:**
```python
# 1. Load raw data vÃ  phÃ¢n tÃ­ch columns
categorical_cols = [col for col in df.columns if col.endswith('_encoded')]
numerical_cols = [col for col in df.columns if not categorical]

# 2. Prepare data theo features type
if features == 'MS':
    data = [target] + numerical + categorical
elif features == 'M':  
    data = numerical + categorical
else:  # 'S'
    data = [target] only

# 3. Train/Val/Test split theo timestamp
borders = [0, train_end, val_end, test_end]

# 4. Return processed data
return seq_x, seq_y, seq_x_mark, seq_y_mark, categorical_data
```

#### 2. **Dataset_MultiRegion_Embedding** 
**Má»¥c Ä‘Ã­ch:** Má»Ÿ rá»™ng embedding approach cho multiple regions Ä‘á»“ng thá»i

**Äáº·c Ä‘iá»ƒm:**
- **Multi-region Support**: Xá»­ lÃ½ nhiá»u regions (LATAM, Europe, USCA) trong má»™t model
- **Region-aware Sequences**: Má»—i sequence bao gá»“m thÃ´ng tin region
- **Combined Training**: Táº¡o training set tá»« táº¥t cáº£ regions
- **Region ID Tracking**: Theo dÃµi sequence thuá»™c region nÃ o

#### 3. **Dataset_SupplyChain_Processed**
**File:** `data_loader_supply_chain.py` 

**Má»¥c Ä‘Ã­ch:** Standard approach khÃ´ng dÃ¹ng embedding, xá»­ lÃ½ numerical features only

**Use cases:**
- Baseline comparison vá»›i embedding approach
- Fallback option khi embedding khÃ´ng stable
- Performance benchmarking

#### 4. **Dataset_SupplyChain_MultiMarket**
**Má»¥c Ä‘Ã­ch:** Xá»­ lÃ½ Ä‘á»“ng thá»i multiple markets vá»›i shared architecture

## Ká»¹ thuáº­t Xá»­ lÃ½ Dá»¯ liá»‡u

### ğŸ¯ Feature Engineering Pipeline

#### Categorical Features Processing:
```python
# Detect categorical columns (cÃ³ suffix '_encoded')
categorical_cols = [col for col in df.columns if col.endswith('_encoded')]

# Convert to embeddings trong model
for col in categorical_cols:
    categorical_data[col.replace('_encoded', '')] = torch.tensor(data, dtype=torch.long)
```

#### Numerical Features Processing:
```python
# Auto-detect numerical columns
numerical_cols = [col for col in df.columns if col not in [date_col, target] + categorical_cols]

# Scaling
if scale:
    scaler.fit(train_data[numerical_cols])
    numerical_data = scaler.transform(numerical_data)
```

#### Time Features Processing:
```python
# Time encoding options
if timeenc == 0:
    time_features = time_features(pd.to_datetime(timestamp), freq=freq)
elif timeenc == 1:
    time_features = time_features(pd.to_datetime(timestamp), freq=freq)
```

### ğŸ”„ Sequence Generation Logic

**Sliding Window Approach:**
```python
# Táº¡o sequences cho time series
def __getitem__(self, index):
    s_begin = index                          # Start cá»§a input sequence
    s_end = s_begin + seq_len               # End cá»§a input sequence  
    r_begin = s_end - label_len             # Start cá»§a prediction sequence
    r_end = r_begin + label_len + pred_len  # End cá»§a prediction sequence
    
    seq_x = data[s_begin:s_end]             # Input sequence
    seq_y = data[r_begin:r_end]             # Target sequence
```

**Train/Val/Test Split:**
```python
# Temporal split Ä‘á»ƒ trÃ¡nh data leakage
border1s = [0, num_train - seq_len, len(df_data) - num_test - seq_len]
border2s = [num_train, len(df_data) - num_test, len(df_data)]
```

## Custom Collate Function

### ğŸ”§ Embedding Collate Function
**Má»¥c Ä‘Ã­ch:** Xá»­ lÃ½ batch data cÃ³ chá»©a categorical embeddings

```python
def embedding_collate_fn(batch):
    # Separate regular tensors vÃ  categorical features
    seq_x, seq_y, seq_x_mark, seq_y_mark, categorical_features = zip(*batch)
    
    # Stack regular tensors
    seq_x = torch.stack([torch.FloatTensor(x) for x in seq_x])
    seq_y = torch.stack([torch.FloatTensor(y) for y in seq_y])
    
    # Handle categorical features
    batch_categorical = {}
    for key in categorical_features[0].keys():
        batch_categorical[key] = torch.stack([cat_feat[key] for cat_feat in categorical_features])
```

## Cáº¥u hÃ¬nh vÃ  Sá»­ dá»¥ng

### ğŸ“‹ Arguments Mapping
```python
# Dataset selection
args.data = 'SupplyChainEmbedding'  # Chá»n embedding approach

# Sequence parameters  
args.seq_len = 7     # Input sequence length (7 days)
args.label_len = 1   # Label length for decoder
args.pred_len = 1    # Prediction horizon (1 day)

# Feature configuration
args.features = 'MS'  # 'MS': multivariate, 'M': no target, 'S': univariate
args.target = 'Order Item Quantity'  # Target column name

# Data path
args.data_path = 'seller_Order_Region_processed.csv'  # Input file
```

### ğŸš€ Usage Example
```python
# Trong run.py hoáº·c experiment
from data_provider.data_factory import data_provider

# Táº¡o train dataloader
train_data, train_loader = data_provider(args, flag='train')

# Táº¡o validation dataloader  
vali_data, vali_loader = data_provider(args, flag='val')

# Táº¡o test dataloader
test_data, test_loader = data_provider(args, flag='test')

# Iterate qua data
for batch_x, batch_y, batch_x_mark, batch_y_mark, categorical_data in train_loader:
    # batch_x: Input sequences [batch_size, seq_len, features]
    # batch_y: Target sequences [batch_size, pred_len, 1] 
    # categorical_data: Dict chá»©a embedding indices
```

## Tá»‘i Æ°u Performance

### âš¡ Memory Optimization
- **Lazy Loading**: Dataset chá»‰ load data khi cáº§n thiáº¿t
- **Efficient Indexing**: Sá»­ dá»¥ng iloc cho pandas indexing
- **Custom Collate**: Minimize memory copy operations

### ğŸ”„ Training Optimization  
- **Shuffle Strategy**: Random shuffle cho train, sequential cho test
- **Batch Size**: Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh dá»±a trÃªn memory available
- **Num Workers**: Parallel data loading Ä‘á»ƒ tÄƒng tá»‘c

## Phase 2 Expansion Plan

### ğŸ¯ Upcoming Features
1. **External Data Integration**: ThÃªm weather, holiday, economic indicators
2. **Dynamic Feature Selection**: Auto feature engineering
3. **Advanced Scaling**: Per-region, per-category scaling strategies
4. **Data Augmentation**: Time series augmentation techniques
5. **Real-time Pipeline**: Streaming data processing capability

### ğŸ”§ Architecture Improvements
- **Modular Design**: TÃ¡ch biá»‡t feature engineering components
- **Plugin System**: Dá»… dÃ ng thÃªm new data sources
- **Caching Layer**: Cache processed data Ä‘á»ƒ tÄƒng tá»‘c training
- **Monitoring**: Data quality monitoring vÃ  alerting

## Troubleshooting

### â— Common Issues
1. **Memory Error**: Giáº£m batch_size hoáº·c tÄƒng num_workers
2. **Data Shape Mismatch**: Kiá»ƒm tra seq_len, pred_len configuration
3. **Categorical Encoding**: Äáº£m báº£o categorical columns cÃ³ suffix '_encoded'
4. **Time Features**: Kiá»ƒm tra date column format vÃ  freq parameter

### ğŸ” Debug Commands
```python
# Check dataset info
print(f"Dataset length: {len(data_set)}")
print(f"Data shape: {data_set[0][0].shape}")
print(f"Categorical features: {data_set.categorical_cols}")

# Verify data loading
sample_batch = next(iter(data_loader))
print(f"Batch shapes: {[x.shape for x in sample_batch[:4]]}")
```

Há»‡ thá»‘ng data provider nÃ y Ä‘Ã£ Ä‘Æ°á»£c optimize vÃ  test ká»¹ lÆ°á»¡ng trong Phase 1, Ä‘áº¡t **98.71% improvement** so vá»›i baseline. Code structure rÃµ rÃ ng, dá»… maintain vÃ  extend cho Phase 2.
